{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://teaching.bowyer.ai/sdsai/0/img/IMPERIAL_logo_RGB_Blue_2024.svg\" alt=\"Imperial Logo\" width=\"500\"/><br /><br />\n",
    "\n",
    "Programming, Manipulating and Visualising Data - Challenge Exercise 1 Solutions\n",
    "==============\n",
    "### SURG70098 - Surgical Data Science and AI\n",
    "### Stuart Bowyer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas_gbq --quiet\n",
    "import pandas_gbq\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# @markdown Enter your Google Cloud Project ID:\n",
    "project_id = 'mimic-test-12345'  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 1 - Exploring the Patient Table\n",
    "\n",
    "## Part 1a - Load the `patients` table\n",
    "\n",
    "* Load the table (using the function from the lecture notes)\n",
    "* Print it to check you have the right data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query to load data from BigQuery\n",
    "df_patients = pandas_gbq.read_gbq(\"\"\"\n",
    " SELECT * FROM `physionet-data.mimiciv_3_1_hosp.patients`\n",
    "\"\"\", project_id=project_id)\n",
    "\n",
    "# Now print the first few rows of the dataframe\n",
    "print(df_patients.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1b - Check the data types for each column\n",
    "\n",
    "* Use the MIMIC documentation to understand what each column is\n",
    "* What do you notice about the dates - unlike when loading a CSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1c - Compute the gender rates\n",
    "\n",
    "* Start by exploring which values are in the column (`.unique()` might help)\n",
    "* Compute the number of patients for each\n",
    "* Compute the percentages of total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step (explicit) approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique GENDER values\n",
    "genders = df_patients['GENDER'].unique()\n",
    "print(f\"Unique genders: {genders}\")\n",
    "\n",
    "# Count the number of patients for each gender\n",
    "male_count = sum(df_patients['GENDER'] == 'M')\n",
    "female_count = sum(df_patients['GENDER'] == 'F')\n",
    "print(f\"Number of male patients: {male_count}, Number of female patients: {female_count}\")\n",
    "\n",
    "# Compute the percentages\n",
    "total_count = len(df_patients)\n",
    "male_percentage = (male_count / total_count) * 100\n",
    "female_percentage   = (female_count / total_count) * 100\n",
    "print(f\"Percentage of male patients: {male_percentage} %, Percentage of female patients: {female_percentage} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-liner pandas Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The one-liner option\n",
    "proportions = df_patients['GENDER'].value_counts(normalize=True) * 100\n",
    "print(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1d - Visualise the gender rates\n",
    "\n",
    "* Use an appropriate visualisation method of your choice to display the gender rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts\n",
    "gender_counts = df_patients['GENDER'].value_counts()\n",
    "\n",
    "# Create the plot directly with plt.bar()\n",
    "# Pass the categories (index) as x and counts (values) as y\n",
    "plt.bar(gender_counts.index, gender_counts.values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Distribution of Genders')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Exploring Diagnosis Data\n",
    "\n",
    "## Part 2a - Load the diagnosis table\n",
    "\n",
    "* Load the table (using the function from the lecture notes)\n",
    "* Print it to check you have the right data\n",
    "* **NOTE - this is a big table** you should just work with a small part of it for now (use `LIMIT 10000` in your SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first 10,000 rows of the icd_diagnoses table\n",
    "df_diagnoses = pandas_gbq.read_gbq(\"\"\"\n",
    "SELECT * FROM `physionet-data.mimiciv_3_1_hosp.diagnoses_icd` LIMIT 1000000\n",
    "\"\"\", project_id=project_id)\n",
    "\n",
    "print(df_diagnoses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2b - Check the structure and types\n",
    "\n",
    "* Use the MIMIC documentation to understand what each column is\n",
    "* How can we link a diagnosis to a patient?\n",
    "* How can we link a diagnosis to a date/time?\n",
    "* How are diagnoses encoded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses.dtypes\n",
    "\n",
    "# SUBJECT_ID links to patients\n",
    "# HADM_ID links to hospital admissions - which in turn links to date/time of an event\n",
    "# ICD9_CODE is the diagnosis code, coded using the ICD-9 system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2c - Count number of atrial fibrillation diagnoses in the dataset\n",
    "\n",
    "* The ICD-9 code for Atrial fibrillation is 427.31 **coded in MIMIC as 42731**\n",
    "* You can use your `LIMIT`ed dataset for this, but remember you're not actually looking at all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where ICD9_CODE is '42731' (Atrial fibrillation)\n",
    "df_afib = df_diagnoses[df_diagnoses['ICD9_CODE'] == '42731']\n",
    "\n",
    "n_afib = len(df_afib)\n",
    "print(f\"Number of atrial fibrillation diagnoses in the dataset: {n_afib}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2d - Count number of patients with atrial fibrillation diagnoses\n",
    "\n",
    "* You might want to use `.nunique()` to find the number of unique values in a given column\n",
    "* What does comparing this result to that in the previous section tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_afib_patients = df_afib['SUBJECT_ID'].nunique()\n",
    "print(f\"Number of patients with atrial fibrillation diagnoses in the dataset: {n_afib_patients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact there are fewer patients with atrial fibrillation than total diagnoses of atrial fibrillation shows that some patients have multiple repeated diagnoses. This is important to be aware of. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2e - Compute and visualise the gender breakdown of patients with atrial fibrilation\n",
    "\n",
    "* This requires combining the diagnosis and patients tables\n",
    "* There are many ways to achieve this, but here is a suggest set of steps:\n",
    "    * Get a `SUBJECT_ID` column that defines all the patients with atrial fibrilation\n",
    "    * Use the `.merge` to combine the `patients` table with this list of patients\n",
    "    * Use the analysis methods from part 1 on the resulting table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: get a dataframe of patients with atrial fibrillation\n",
    "df_afib_patients = df_afib['SUBJECT_ID'].drop_duplicates()\n",
    "\n",
    "# Step 2: merge with the patients dataframe\n",
    "df_afib_patients = df_patients.merge(df_afib, how='inner', on='SUBJECT_ID')\n",
    "\n",
    "# Step 3: visualise the gender split\n",
    "gender_counts = df_afib_patients['GENDER'].value_counts()\n",
    "plt.bar(gender_counts.index, gender_counts.values)\n",
    "plt.title('Distribution of Genders with Atrial Fibrillation')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Defining a Sepsis Cohort\n",
    "\n",
    "In this exercise, we will compute several characteristics of patients in the MIMIC-IV dataset with sepsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3a - Identifying a patient cohort list\n",
    "\n",
    "* Explore ways to identify the list of `SUBJECT_ID`s for patients with sepsis\n",
    "* There are multiple ways you can do this, ask and we can discuss options\n",
    "\n",
    "### Hints\n",
    "\n",
    "This step is very similar to what you did in Part 2. You will query the `diagnoses_icd` table and then filter it in Pandas.\n",
    "\n",
    "1.  Load a *sample* of the `diagnoses_icd` table. Remember, it's a big table, so use `LIMIT`. `LIMIT 100000` is a good starting point.\n",
    "    * *Query:* `SELECT * FROM physionet-data.mimiciv_3_1_hosp.diagnoses_icd LIMIT 100000`\n",
    "    * Load this into a DataFrame, e.g., `df_diagnoses`.\n",
    "    * You might already have this loaded so can skip this\n",
    "2.  The ICD-9 codes for 'Sepsis' is 99591 and 'Septic shock' is 78552.\n",
    "3.  You need to filter your `df_diagnoses` to find rows where the `icd_code` is one of these two values.\n",
    "    * *Hint:* The `.isin()` method is perfect for this:\n",
    "        `df_diagnoses[df_diagnoses['icd_code'].isin(['99591', '78552'])]`\n",
    "4.  Store this filtered data in a new DataFrame, e.g., `df_sepsis`.\n",
    "5.  You might want to get a unique list of admissions by using `.drop_duplicates(subset=['hadm_id'])`. This DataFrame is your sepsis cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sepsis = df_diagnoses[df_diagnoses['icd_code'].isin(['99591', '78552'])]\n",
    "df_sepsis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3b - Identifying an associated set of admissions\n",
    "\n",
    "* Knowing which patients have sepsis is only half the challenge, you also need to identify **when** they had sepsis\n",
    "* Start by looking at the `admissions` table and identify which are associated with a sepsis event\n",
    "\n",
    "### Hints\n",
    "\n",
    "Now your goal is to get more details about the *admissions* for the cohort you just identified in `df_sepsis`. This will help you find out *when* they were admitted.\n",
    "\n",
    "1.  First, load a sample of the `admissions` table. This table is not too big, but using a `LIMIT 100000` is still a good, safe practice.\n",
    "    * *Query:* `SELECT * FROM physionet-data.mimiciv_3_1_hosp.admissions LIMIT 100000`\n",
    "    * Load this into a new DataFrame, e.g., `df_admissions`.\n",
    "2.  Now, `merge` your `df_sepsis` (from 3a) with `df_admissions`.\n",
    "    * You will want to merge these on the `hadm_id` column, as both tables share it.\n",
    "    * `df_sepsis_admissions = pd.merge(df_sepsis, df_admissions, on='hadm_id')`\n",
    "3.  This new `df_sepsis_admissions` DataFrame now contains all the rows from `df_admissions` that correspond to a sepsis diagnosis *in your sample*. It will have the `admittime` and `dischtime` columns you need for the next step.\n",
    "    * **Note:** Your result might be small if your `LIMIT`ed samples didn't overlap much. This is expected and is fine for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admissions = pandas_gbq.read_gbq(\"\"\"\n",
    "SELECT * FROM `physionet-data.mimiciv_3_1_hosp.admissions`\n",
    "\"\"\", project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using an `inner` merge here, because:\n",
    "1. We need data when there is a sepsis code AND an admission (though this should always be the case)\n",
    "2. In the event that there are two records on sepsis against a single admission, we only want one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sepsis_admissions = df_sepsis.merge(df_admissions, how='inner', on=['hadm_id', 'subject_id'])\n",
    "df_sepsis_admissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3c - Basic sepsis cohort characteristics\n",
    "\n",
    "* Explore and visualise the gender split and length of stay distribution for your sepsis cohort\n",
    "\n",
    "### Hints\n",
    "\n",
    "You will use the DataFrames you've already created.\n",
    "\n",
    "**Gender Analysis**\n",
    "\n",
    "1.  You need two DataFrames:\n",
    "    * `df_sepsis_admissions` (from Part 3b)\n",
    "    * `df_patients` (from Part 1)\n",
    "2.  `merge` these two DataFrames on `subject_id`.\n",
    "3.  The resulting DataFrame will have both `gender` and admission data. You can now analyze the `gender` column (e.g., `.value_counts()`) and visualize it.\n",
    "\n",
    "**Length of Stay (LOS) Analysis**\n",
    "\n",
    "1.  This is even easier! The DataFrame `df_sepsis_admissions` (which you created in Part 3b) *already* has the `admittime` and `dischtime` columns.\n",
    "2.  Check the data types with `.info()`. The `admittime` and `dischtime` columns should be datetime objects.\n",
    "3.  You can create a new `los` column by subtracting the `admittime` from the `dischtime`:\n",
    "    ```python\n",
    "    df_sepsis_admissions['los'] = df_sepsis_admissions['dischtime'] - df_sepsis_admissions['admittime']\n",
    "    ```\n",
    "4.  This will give you a `timedelta` object. To get the LOS in days (as a number), you can use the `.dt.total_seconds()` accessor and divide:\n",
    "    ```python\n",
    "    df_sepsis_admissions['los_days'] = df_sepsis_admissions['los'].dt.total_seconds() / (60*60*24)\n",
    "    ```\n",
    "5.  Now you can plot a histogram of this `los_days` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sepsis_admissions_patients = df_sepsis_admissions.merge(df_patients, how='inner', on='subject_id')\n",
    "\n",
    "# Visualise the gender split\n",
    "gender_counts = df_sepsis_admissions_patients['gender'].value_counts()\n",
    "plt.bar(gender_counts.index, gender_counts.values)\n",
    "plt.title('Distribution of Genders with Sepsis')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sepsis_admissions['los'] = df_sepsis_admissions['dischtime'] - df_sepsis_admissions['admittime']\n",
    "df_sepsis_admissions['los_days'] = df_sepsis_admissions['los'].dt.total_seconds() / (60*60*24)\n",
    "\n",
    "df_sepsis_admissions.hist(column='los_days', bins=110)\n",
    "plt.xlim(0, 50)  # Set x-axis limits from 0 to 50 days - the tail is long and sparse\n",
    "plt.title('Length of Stay Distribution (0-50 days)')\n",
    "plt.xlabel('Length of Stay (days)')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3d - Plot a single patient's heart rate\n",
    "\n",
    "* Pick any single patient from your cohort and plot their heart rate observations during the admission\n",
    "* You will need to use the `chartevents` and `d_items` tables\n",
    "* `d_items` is a 'dictionary' that lets you lookup event codes for specific types of observation\n",
    "\n",
    "### Hints\n",
    "\n",
    "The `chartevents` table is **massive** (it has billions of rows).\n",
    "\n",
    "**DO NOT** try to load this table without a `LIMIT`. You **must** query a small sample. This is the only way to do this analysis in Pandas.\n",
    "\n",
    "**Step 1: Find the `itemid` for Heart Rate**\n",
    "1.  Load the `d_items` (dictionary) table.\n",
    "    * *Query:* `SELECT * FROM physionet-data.mimiciv_3_1_icu.d_items`\n",
    "    * Load into `df_d_items`.\n",
    "2.  Filter this DataFrame in Pandas to find the `itemid` for 'Heart Rate'.\n",
    "    * `hr_itemid = df_d_items[df_d_items['label'] == 'Heart Rate']`\n",
    "\n",
    "**Step 2: Load a Sample of `chartevents` and filter for Heart Rate**\n",
    "1.  Load a **sample** of the `chartevents` table. A `LIMIT 1000000` (one million) is a good start. This will still be a large query.\n",
    "    * *Query:* `SELECT * FROM physionet-data.mimiciv_icu.chartevents LIMIT 1000000`\n",
    "    * Load into `df_chartevents`.\n",
    "2.  Filter this `df_chartevents` to *only* keep rows for Heart Rate.\n",
    "    * `df_hr = df_chartevents[df_chartevents['itemid'] == hr_itemid].copy()`\n",
    "    * This `df_hr` DataFrame now contains all heart rate measurements *from your sample*.\n",
    "\n",
    "**Step 3: Plot a single patient's heart rate (Part 3d)**\n",
    "1.  Look at your `df_sepsis_admissions` (from 3b) and pick any single `hadm_id`.\n",
    "2.  Filter your `df_hr` (from Step 2) to get the rows for *only* that one `hadm_id`.\n",
    "    * `df_one_patient_hr = df_hr[df_hr['hadm_id'] == <your_chosen_hadm_id>]`\n",
    "3.  This `df_one_patient_hr` will be small. You can now plot `valuenum` (the HR value) vs. `charttime` (the time) using a line plot.\n",
    "    * *Hint:* You might want to `sort_values('charttime')` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First load and check the d_items dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d_items = pandas_gbq.read_gbq(\"\"\"\n",
    "SELECT * FROM `physionet-data.mimiciv_3_1_icu.d_items`\n",
    "\"\"\", project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we search for heart rate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_items = df_d_items[df_d_items['label'].str.contains('Heart Rate', case=False, na=False)]\n",
    "hr_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "220045 is the itemid we are looking for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_itemid = df_d_items[df_d_items['label'] == 'Heart Rate']['itemid'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the vitalsigns\n",
    "\n",
    "Though you can just `LIMIT`, I'm going to use a small bit of extra SQL to load all of the HR values for just our sepsis patients\n",
    "\n",
    "By adding `WHERE itemid = 220045` I only pull down rows from chartevents where the itemid is 220045, which is the heart rate.\n",
    "\n",
    "By also adding `subject_id IN ({sepsis_subjects_str})` I filter only the patients in our sepsis cohort.\n",
    "\n",
    "It's still a big table, but can be loaded in under a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of subject IDs from sepsis admissions\n",
    "sepsis_subjects = df_sepsis_admissions['subject_id'].unique().tolist()\n",
    "sepsis_subjects_str = ','.join(map(str, sepsis_subjects))\n",
    "\n",
    "# Now load only the heart rate data for sepsis patients\n",
    "df_chartevents = pandas_gbq.read_gbq(f\"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    `physionet-data.mimiciv_3_1_icu.chartevents`\n",
    "WHERE\n",
    "    itemid = 220045\n",
    "    AND subject_id IN ({sepsis_subjects_str})\n",
    "\"\"\", project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter the chartevents to only get the HR values.\n",
    "\n",
    "In this case, we already did this in SQL, but good to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = df_chartevents[df_chartevents['itemid'] == hr_itemid].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now plot a single admission's HR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random admission (27045774)\n",
    "df_one_patient_hr = df_hr[df_hr['hadm_id'] == 27045774]\n",
    "\n",
    "# Sort the 'charttime' so that the plot shows them in order\n",
    "df_one_patient_hr = df_one_patient_hr.sort_values('charttime')\n",
    "\n",
    "# Simple line plot\n",
    "df_one_patient_hr.plot(x='charttime', y='valuenum', title='Heart Rate over Time for one Sepsis Patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3e - Analyse and visualise the distribution of heart rate values for patients in your cohort\n",
    "\n",
    "* Extract heart rate values for every sepsis admission in your cohort\n",
    "* Visualise the distribution of these values in an appropriate way\n",
    "\n",
    "### Hints\n",
    "\n",
    "1.  You need to find all the heart rates that belong to your sepsis cohort.\n",
    "2.  `merge` your `df_sepsis_admissions` (from 3b) with your `df_hr` (from Step 2).\n",
    "    * You should merge on `hadm_id`.\n",
    "    * `df_sepsis_hr = pd.merge(df_sepsis_admissions, df_hr, on='hadm_id')`\n",
    "3.  This `df_sepsis_hr` DataFrame now *only* contains heart rate measurements for the sepsis patients found in your samples.\n",
    "4.  You can now plot a histogram of the `valuenum` column from `df_sepsis_hr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the sepsis admissions with the heart rate data\n",
    "df_sepsis_hr = pd.merge(df_sepsis_admissions, df_hr, on='hadm_id')\n",
    "\n",
    "# Plot the distribution of heart rate values\n",
    "df_sepsis_hr.hist(column='valuenum', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works ok, but for anything more realistic, we would probably want to consider the repeated observations and take the average per patient or per day or some other way to normalise and avoid bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 1 - Repeat above using an alternative sepsis definition\n",
    "\n",
    "* There is a `microbiology` table"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "teaching-bowyer-ai-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "title": "Programming for Data Science and AI"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
